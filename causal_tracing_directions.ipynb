{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c29917",
   "metadata": {},
   "source": [
    "# Causal Tracing and Feature Directions\n",
    "\n",
    "This notebook demonstrates advanced mechanistic interpretability techniques: causal tracing to understand information flow and feature direction analysis to understand how concepts are represented geometrically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb1cc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79730e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    def get_layer_activations(self, x, layer_name):\n",
    "        x = x.view(-1, 784)\n",
    "        activations = {}\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if layer_name == 'fc1':\n",
    "            activations['fc1'] = x.clone()\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if layer_name == 'fc2':\n",
    "            activations['fc2'] = x.clone()\n",
    "\n",
    "        x = F.relu(self.fc3(x))\n",
    "        if layer_name == 'fc3':\n",
    "            activations['fc3'] = x.clone()\n",
    "\n",
    "        x = self.fc4(x)\n",
    "        if layer_name == 'fc4':\n",
    "            activations['fc4'] = x.clone()\n",
    "\n",
    "        return activations.get(layer_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533d68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "transform = transforms.ToTensor()\n",
    "train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b613c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=5):\n",
    "    \"\"\"Train the MNIST model\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}, Average Loss: {total_loss/len(train_loader):.4f}')\n",
    "    \n",
    "    print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4c7ace",
   "metadata": {},
   "source": [
    "## Feature Direction Analysis\n",
    "\n",
    "Understand what directions in activation space correspond to specific concepts (digits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067cd536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_digit_directions(model, data_loader, layer_name='fc2'):\n",
    "    \"\"\"Find the direction in activation space that best separates each digit\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    digit_activations = {i: [] for i in range(10)}\n",
    "    \n",
    "    # Collect activations for each digit\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            activations = model.get_layer_activations(data, layer_name)\n",
    "            \n",
    "            for digit in range(10):\n",
    "                digit_mask = (target == digit)\n",
    "                if digit_mask.sum() > 0:\n",
    "                    digit_activations[digit].append(activations[digit_mask])\n",
    "    \n",
    "    # Compute mean activation for each digit\n",
    "    digit_means = {}\n",
    "    for digit in range(10):\n",
    "        if digit_activations[digit]:\n",
    "            all_acts = torch.cat(digit_activations[digit], dim=0)\n",
    "            digit_means[digit] = all_acts.mean(dim=0)\n",
    "    \n",
    "    # Compute overall mean\n",
    "    all_means = torch.stack(list(digit_means.values()))\n",
    "    global_mean = all_means.mean(dim=0)\n",
    "    \n",
    "    # Compute digit-specific directions (difference from global mean)\n",
    "    digit_directions = {}\n",
    "    for digit in range(10):\n",
    "        digit_directions[digit] = digit_means[digit] - global_mean\n",
    "    \n",
    "    return digit_directions, digit_means, global_mean\n",
    "\n",
    "def visualize_digit_directions(digit_directions):\n",
    "    \"\"\"Visualize the most important dimensions for each digit\"\"\"\n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for digit in range(10):\n",
    "        direction = digit_directions[digit].cpu().numpy()\n",
    "        \n",
    "        # Plot the direction vector\n",
    "        axes[digit].bar(range(len(direction)), direction, alpha=0.7)\n",
    "        axes[digit].set_title(f'Digit {digit} Direction Vector')\n",
    "        axes[digit].set_xlabel('Neuron Index')\n",
    "        axes[digit].set_ylabel('Direction Magnitude')\n",
    "        \n",
    "        # Highlight top positive and negative neurons\n",
    "        top_pos = np.argsort(direction)[-5:]\n",
    "        top_neg = np.argsort(direction)[:5]\n",
    "        \n",
    "        for idx in top_pos:\n",
    "            axes[digit].bar(idx, direction[idx], color='red', alpha=0.8)\n",
    "        for idx in top_neg:\n",
    "            axes[digit].bar(idx, direction[idx], color='blue', alpha=0.8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_direction_orthogonality(digit_directions):\n",
    "    \"\"\"Analyze how orthogonal the digit directions are\"\"\"\n",
    "    direction_matrix = torch.stack([digit_directions[i] for i in range(10)])\n",
    "    \n",
    "    # Normalize directions\n",
    "    direction_matrix = F.normalize(direction_matrix, dim=1)\n",
    "    \n",
    "    # Compute pairwise cosine similarities\n",
    "    similarity_matrix = torch.mm(direction_matrix, direction_matrix.T).cpu().numpy()\n",
    "    \n",
    "    # Visualize similarity matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(similarity_matrix, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    plt.colorbar(label='Cosine Similarity')\n",
    "    plt.title('Digit Direction Similarities')\n",
    "    plt.xlabel('Digit')\n",
    "    plt.ylabel('Digit')\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            plt.text(j, i, f'{similarity_matrix[i, j]:.2f}', \n",
    "                    ha='center', va='center', \n",
    "                    color='white' if abs(similarity_matrix[i, j]) > 0.5 else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find most similar digit pairs\n",
    "    similar_pairs = []\n",
    "    for i in range(10):\n",
    "        for j in range(i+1, 10):\n",
    "            similar_pairs.append((i, j, similarity_matrix[i, j]))\n",
    "    \n",
    "    similar_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    \n",
    "    print(\"Most similar digit direction pairs:\")\n",
    "    for i, (d1, d2, sim) in enumerate(similar_pairs[:10]):\n",
    "        print(f\"{i+1}. Digits {d1}-{d2}: similarity = {sim:.3f}\")\n",
    "    \n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4785c054",
   "metadata": {},
   "source": [
    "## Causal Intervention Experiments\n",
    "\n",
    "Test what happens when we artificially modify the network's internal representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4daf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_digit_specific_accuracy(model, test_loader, target_digit):\n",
    "    \"\"\"Test accuracy on a specific digit\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            digit_mask = (target == target_digit)\n",
    "            if digit_mask.sum() > 0:\n",
    "                digit_data = data[digit_mask]\n",
    "                digit_target = target[digit_mask]\n",
    "                output = model(digit_data)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                total += digit_target.size(0)\n",
    "                correct += (predicted == digit_target).sum().item()\n",
    "\n",
    "    return 100 * correct / total if total > 0 else 0\n",
    "\n",
    "def intervention_experiment(model, data_loader, digit_directions, layer_name='fc2', target_digit=7):\n",
    "    \"\"\"Test what happens when we artificially enhance the digit direction\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create a modified model that adds the digit direction to activations\n",
    "    class DirectionInterventionHook:\n",
    "        def __init__(self, direction, strength=1.0):\n",
    "            self.direction = direction\n",
    "            self.strength = strength\n",
    "        \n",
    "        def __call__(self, module, input, output):\n",
    "            # Add the direction to all activations\n",
    "            output += self.strength * self.direction.unsqueeze(0)\n",
    "            return output\n",
    "    \n",
    "    # Test with different intervention strengths\n",
    "    strengths = [0, 0.2, 0.5, 1.0, 2.0, 5.0]\n",
    "    results = []\n",
    "    \n",
    "    for strength in strengths:\n",
    "        # Create modified model\n",
    "        modified_model = type(model)()\n",
    "        modified_model.load_state_dict(model.state_dict())\n",
    "        \n",
    "        # Add intervention hook\n",
    "        direction = digit_directions[target_digit].to(next(model.parameters()).device)\n",
    "        hook = DirectionInterventionHook(direction, strength)\n",
    "        \n",
    "        if layer_name == 'fc2':\n",
    "            modified_model.fc2.register_forward_hook(hook)\n",
    "        \n",
    "        # Test accuracy\n",
    "        accuracy = test_digit_specific_accuracy(modified_model, data_loader, target_digit)\n",
    "        results.append(accuracy)\n",
    "        \n",
    "        print(f\"Strength {strength}: Digit {target_digit} accuracy = {accuracy:.2f}%\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(strengths, results, 'o-', linewidth=2, markersize=8)\n",
    "    plt.xlabel('Intervention Strength')\n",
    "    plt.ylabel(f'Digit {target_digit} Accuracy (%)')\n",
    "    plt.title(f'Effect of Enhancing Digit {target_digit} Direction')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "def cross_digit_intervention(model, data_loader, digit_directions, layer_name='fc2'):\n",
    "    \"\"\"Test what happens when we add one digit's direction to another digit's inputs\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Test adding each digit's direction when classifying other digits\n",
    "    intervention_matrix = np.zeros((10, 10))\n",
    "    \n",
    "    for source_digit in range(10):\n",
    "        direction = digit_directions[source_digit].to(next(model.parameters()).device)\n",
    "        \n",
    "        for target_digit in range(10):\n",
    "            # Create modified model\n",
    "            modified_model = type(model)()\n",
    "            modified_model.load_state_dict(model.state_dict())\n",
    "            \n",
    "            # Add intervention hook\n",
    "            class DirectionInterventionHook:\n",
    "                def __init__(self, direction, strength=1.0):\n",
    "                    self.direction = direction\n",
    "                    self.strength = strength\n",
    "                \n",
    "                def __call__(self, module, input, output):\n",
    "                    output += self.strength * self.direction.unsqueeze(0)\n",
    "                    return output\n",
    "            \n",
    "            hook = DirectionInterventionHook(direction, strength=1.0)\n",
    "            \n",
    "            if layer_name == 'fc2':\n",
    "                modified_model.fc2.register_forward_hook(hook)\n",
    "            \n",
    "            # Test accuracy on target digit\n",
    "            accuracy = test_digit_specific_accuracy(modified_model, data_loader, target_digit)\n",
    "            intervention_matrix[source_digit, target_digit] = accuracy\n",
    "    \n",
    "    # Visualize intervention matrix\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(intervention_matrix, cmap='viridis', aspect='auto')\n",
    "    plt.colorbar(label='Accuracy (%)')\n",
    "    plt.title('Cross-Digit Intervention Effects\\n(Adding Source Digit Direction When Classifying Target Digit)')\n",
    "    plt.xlabel('Target Digit (being classified)')\n",
    "    plt.ylabel('Source Digit (direction being added)')\n",
    "    plt.xticks(range(10))\n",
    "    plt.yticks(range(10))\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            plt.text(j, i, f'{intervention_matrix[i, j]:.1f}', \n",
    "                    ha='center', va='center', \n",
    "                    color='white' if intervention_matrix[i, j] < 50 else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return intervention_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391890b",
   "metadata": {},
   "source": [
    "## Causal Tracing\n",
    "\n",
    "Trace how information flows through the network by selectively corrupting and restoring activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corrupted_input(clean_input, corruption_type='noise', strength=0.5):\n",
    "    \"\"\"Create corrupted version of input for causal tracing\"\"\"\n",
    "    if corruption_type == 'noise':\n",
    "        noise = torch.randn_like(clean_input) * strength\n",
    "        return clean_input + noise\n",
    "    elif corruption_type == 'zero':\n",
    "        return torch.zeros_like(clean_input)\n",
    "    elif corruption_type == 'random':\n",
    "        return torch.rand_like(clean_input)\n",
    "    elif corruption_type == 'shuffle':\n",
    "        # Shuffle pixels\n",
    "        flat = clean_input.view(-1)\n",
    "        shuffled = flat[torch.randperm(flat.size(0))]\n",
    "        return shuffled.view_as(clean_input)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown corruption type: {corruption_type}\")\n",
    "\n",
    "def trace_information_flow(model, clean_input, corrupted_input, target_class):\n",
    "    \"\"\"\n",
    "    Trace how different layers contribute to the final prediction\n",
    "    by restoring clean activations layer by layer in a corrupted network\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get clean prediction\n",
    "    with torch.no_grad():\n",
    "        clean_output = model(clean_input)\n",
    "        clean_prob = F.softmax(clean_output, dim=1)[0, target_class].item()\n",
    "    \n",
    "    # Get corrupted prediction  \n",
    "    with torch.no_grad():\n",
    "        corrupted_output = model(corrupted_input)\n",
    "        corrupted_prob = F.softmax(corrupted_output, dim=1)[0, target_class].item()\n",
    "    \n",
    "    print(f\"Clean probability: {clean_prob:.3f}\")\n",
    "    print(f\"Corrupted probability: {corrupted_prob:.3f}\")\n",
    "    print(f\"Total effect: {clean_prob - corrupted_prob:.3f}\")\n",
    "    \n",
    "    # Test restoration at each layer\n",
    "    layers = ['fc1', 'fc2', 'fc3']\n",
    "    restoration_effects = []\n",
    "    \n",
    "    for layer_name in layers:\n",
    "        # Create model with restoration hook at this layer\n",
    "        restored_model = type(model)()\n",
    "        restored_model.load_state_dict(model.state_dict())\n",
    "        \n",
    "        # Get clean activations at this layer\n",
    "        clean_activation = model.get_layer_activations(clean_input, layer_name)\n",
    "        \n",
    "        class RestorationHook:\n",
    "            def __init__(self, clean_activation):\n",
    "                self.clean_activation = clean_activation\n",
    "            \n",
    "            def __call__(self, module, input, output):\n",
    "                return self.clean_activation\n",
    "        \n",
    "        # Add hook to restore clean activations\n",
    "        if layer_name == 'fc1':\n",
    "            restored_model.fc1.register_forward_hook(RestorationHook(clean_activation))\n",
    "        elif layer_name == 'fc2':\n",
    "            restored_model.fc2.register_forward_hook(RestorationHook(clean_activation))\n",
    "        elif layer_name == 'fc3':\n",
    "            restored_model.fc3.register_forward_hook(RestorationHook(clean_activation))\n",
    "        \n",
    "        # Get restored prediction\n",
    "        with torch.no_grad():\n",
    "            restored_output = restored_model(corrupted_input)\n",
    "            restored_prob = F.softmax(restored_output, dim=1)[0, target_class].item()\n",
    "        \n",
    "        effect = restored_prob - corrupted_prob\n",
    "        restoration_effects.append(effect)\n",
    "        print(f\"Restoring {layer_name}: probability = {restored_prob:.3f}, effect = {effect:.3f}\")\n",
    "    \n",
    "    return restoration_effects\n",
    "\n",
    "def run_causal_tracing_experiment(model, data_loader, num_examples=5):\n",
    "    \"\"\"Run causal tracing on multiple examples with different corruption types\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    corruption_types = ['noise', 'shuffle', 'zero']\n",
    "    all_effects = {corruption: [] for corruption in corruption_types}\n",
    "    \n",
    "    example_count = 0\n",
    "    for data, target in data_loader:\n",
    "        if example_count >= num_examples:\n",
    "            break\n",
    "            \n",
    "        for i in range(min(1, data.size(0))):\n",
    "            clean_input = data[i:i+1]\n",
    "            true_label = target[i].item()\n",
    "            \n",
    "            # Get model prediction\n",
    "            with torch.no_grad():\n",
    "                pred = model(clean_input).argmax().item()\n",
    "            \n",
    "            if pred == true_label:  # Only analyze correctly classified examples\n",
    "                print(f\"\\n--- Example {example_count + 1}: Digit {true_label} ---\")\n",
    "                \n",
    "                for corruption in corruption_types:\n",
    "                    print(f\"\\nCorruption type: {corruption}\")\n",
    "                    \n",
    "                    # Create corrupted input\n",
    "                    corrupted_input = create_corrupted_input(clean_input, corruption, 0.5)\n",
    "                    \n",
    "                    # Run causal tracing\n",
    "                    effects = trace_information_flow(model, clean_input, corrupted_input, true_label)\n",
    "                    all_effects[corruption].append(effects)\n",
    "                \n",
    "                example_count += 1\n",
    "                break\n",
    "    \n",
    "    # Plot average effects\n",
    "    layers = ['fc1', 'fc2', 'fc3']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    for i, corruption in enumerate(corruption_types):\n",
    "        if all_effects[corruption]:\n",
    "            avg_effects = np.mean(all_effects[corruption], axis=0)\n",
    "            std_effects = np.std(all_effects[corruption], axis=0)\n",
    "            \n",
    "            axes[i].bar(layers, avg_effects, yerr=std_effects, capsize=5, alpha=0.7)\n",
    "            axes[i].set_title(f'Restoration Effects\\n({corruption} corruption)')\n",
    "            axes[i].set_xlabel('Layer Restored')\n",
    "            axes[i].set_ylabel('Probability Recovery')\n",
    "            axes[i].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return all_effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dd0b4",
   "metadata": {},
   "source": [
    "## Linear Probing\n",
    "\n",
    "Train linear classifiers on internal representations to understand what information is linearly accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1232eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_probing_analysis(model, data_loader, max_samples=2000):\n",
    "    \"\"\"Train linear probes on each layer to see what information is linearly accessible\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    layers = ['fc1', 'fc2', 'fc3', 'fc4']\n",
    "    layer_data = {layer: {'activations': [], 'labels': []} for layer in layers}\n",
    "    \n",
    "    sample_count = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in data_loader:\n",
    "            if sample_count >= max_samples:\n",
    "                break\n",
    "            \n",
    "            for layer in layers:\n",
    "                activations = model.get_layer_activations(data, layer)\n",
    "                layer_data[layer]['activations'].append(activations.cpu().numpy())\n",
    "                layer_data[layer]['labels'].append(target.cpu().numpy())\n",
    "            \n",
    "            sample_count += data.size(0)\n",
    "    \n",
    "    # Concatenate data\n",
    "    for layer in layers:\n",
    "        layer_data[layer]['activations'] = np.concatenate(layer_data[layer]['activations'])\n",
    "        layer_data[layer]['labels'] = np.concatenate(layer_data[layer]['labels'])\n",
    "    \n",
    "    # Train linear probes\n",
    "    probe_accuracies = {}\n",
    "    \n",
    "    for layer in layers:\n",
    "        X = layer_data[layer]['activations']\n",
    "        y = layer_data[layer]['labels']\n",
    "        \n",
    "        # Split data\n",
    "        split_idx = int(0.8 * len(X))\n",
    "        X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "        \n",
    "        # Train linear classifier\n",
    "        clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        clf.fit(X_train, y_train)\n",
    "        \n",
    "        # Test accuracy\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred) * 100\n",
    "        probe_accuracies[layer] = accuracy\n",
    "        \n",
    "        print(f\"{layer}: Linear probe accuracy = {accuracy:.2f}%\")\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(layers, [probe_accuracies[layer] for layer in layers], alpha=0.7)\n",
    "    plt.xlabel('Layer')\n",
    "    plt.ylabel('Linear Probe Accuracy (%)')\n",
    "    plt.title('Linear Separability of Digit Classes by Layer')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, layer in enumerate(layers):\n",
    "        plt.text(i, probe_accuracies[layer] + 1, f'{probe_accuracies[layer]:.1f}%', \n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return probe_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d0cf32",
   "metadata": {},
   "source": [
    "## Run Advanced Mechanistic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = MNISTNet()\n",
    "print(\"Training model...\")\n",
    "train_model(model, train_loader, epochs=5)\n",
    "\n",
    "# Test model accuracy\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        output = model(data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eddc8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find digit directions\n",
    "print(\"Finding digit directions in activation space...\")\n",
    "digit_directions, digit_means, global_mean = find_digit_directions(model, test_loader, layer_name='fc2')\n",
    "visualize_digit_directions(digit_directions)\n",
    "similarity_matrix = analyze_direction_orthogonality(digit_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal intervention experiments\n",
    "print(\"Running causal intervention experiments...\")\n",
    "intervention_results = intervention_experiment(model, test_loader, digit_directions, \n",
    "                                             layer_name='fc2', target_digit=7)\n",
    "\n",
    "print(\"\\nRunning cross-digit intervention analysis...\")\n",
    "intervention_matrix = cross_digit_intervention(model, test_loader, digit_directions, layer_name='fc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal tracing experiments\n",
    "print(\"Running causal tracing experiments...\")\n",
    "tracing_effects = run_causal_tracing_experiment(model, test_loader, num_examples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f711b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear probing analysis\n",
    "print(\"Running linear probing analysis...\")\n",
    "probe_accuracies = linear_probing_analysis(model, test_loader, max_samples=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a7dc14",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates advanced mechanistic interpretability techniques:\n",
    "\n",
    "### Feature Direction Analysis\n",
    "- **Concept Directions**: Found directions in activation space corresponding to each digit\n",
    "- **Orthogonality Analysis**: Measured how distinct these concept representations are\n",
    "- **Geometric Understanding**: Revealed how the network organizes concepts geometrically\n",
    "\n",
    "### Causal Intervention\n",
    "- **Direction Enhancement**: Tested what happens when we artificially strengthen digit representations\n",
    "- **Cross-Digit Effects**: Analyzed how adding one digit's direction affects classification of others\n",
    "- **Causal Understanding**: Went beyond correlation to understand causal relationships\n",
    "\n",
    "### Causal Tracing\n",
    "- **Information Flow**: Traced how information flows through network layers\n",
    "- **Critical Layers**: Identified which layers are most important for maintaining predictions\n",
    "- **Corruption Effects**: Tested robustness to different types of input corruption\n",
    "\n",
    "### Linear Probing\n",
    "- **Information Content**: Measured what digit information is linearly accessible at each layer\n",
    "- **Representation Quality**: Showed how representations become more linearly separable in deeper layers\n",
    "\n",
    "These techniques help us understand:\n",
    "- **How** the network represents concepts internally\n",
    "- **Where** critical computations happen\n",
    "- **Why** certain interventions have specific effects\n",
    "- **What** information is preserved or transformed at each layer\n",
    "\n",
    "This represents the cutting edge of mechanistic interpretability - understanding not just what neurons do, but how the network implements its algorithms."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
